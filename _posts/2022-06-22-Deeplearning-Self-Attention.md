---  
layout: archive-taxonomies  
tags: SelfAttention  
categories: Deep_Learning  
---  

# Transformer学习笔记——自注意力机制  
  
*自注意力*（Self-Attention）的具体实现  
计算相关性的方法。  

下面是插入图片的测试：  

![pic:test](/main/screenshot.png)
